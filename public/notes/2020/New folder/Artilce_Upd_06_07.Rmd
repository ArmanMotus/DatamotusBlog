---
title: "Optimization Modeling for Store Product Clustering and EOQ Determination"
author: " "
date: |
  `r format(Sys.time(), '%B %d, %Y')` 
output: 
  html_document:
    css: styles.css
    toc: TRUE
    toc_depth: 4
    toc_float: true
    toc_collapse: true
    theme: united
    highlight: zenburn
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
pacman::p_load(dplyr, ggplot2, stringr, dtw, zoo, kableExtra, wesanderson)
```


```{r}
load("store.data.rda")

store.data <- store.data %>% 
  mutate(PRODUCT = ifelse(NOMINAL == 1000,
                          "Matsuni",
                          ifelse(NOMINAL == 20000,
                          "Milk",
                          "Sour Cream"
                          )))

store.data$NOMINAL <- NULL
colnames(store.data)[3] <- "STORE_ID"
colnames(store.data)[7:8] <- c("Distance from Yerevan","Location")

store.data$Location <- factor(store.data$Location)
store.data$PRODUCT <- factor(store.data$PRODUCT)
store.data$STORE_ID <- factor(store.data$STORE_ID, levels =unique(store.data$STORE_ID) ,labels = str_extract(unique(store.data$STORE_ID), pattern = "[0-9]{3}$"))
```

## Introduction

### Problem Statement

 The *objective* of this study is to develop a robust optimization solution that enables the determination of an optimal replenishment for managing store products. By doing so, store managers can gain valuable insights into the ideal stock levels required to meet customer demand while minimizing holding costs and ensuring efficient inventory management practices. The approach outlined in this article demonstrates the potential to enhance inventory management practices within a retail chain, empowering store managers with accurate and data-driven decision-making capabilities.

   Rather than treating each product and store individually, the group of store will be examined. To address the challenge of defining the economic order quantity (EOQ) for each product and group of store, a clustering approach is applied based on the historical data of available inventory across various product types. 

  The time series clustering is used ensuring that the resulting clusters accurately capture the patterns and trends in inventory levels over time. By clustering stores with similar inventory behaviors, the model can provide recommendations for the optimal number of orders per each cluster and product category.

  Furthermore, this study acknowledges that additional complexities can be addressed beyond the basic EOQ determination. Factors such as optimal replenishment frequency, seasonal variations, and monthly EOQ adjustments can be incorporated into the modeling framework, allowing for more flexible and comprehensive solutions tailored to specific store and product characteristics. Thus, by incorporating advanced analytics and considering various factors, future research can build upon this framework to develop even more sophisticated and customized solutions for inventory optimization.

### Data Description

In this study, we will review a sample dataset obtained from a company specializing in dairy products, focusing on the three most popular types in Armenia. The dataset comprises hourly time series data, covering the period from February 2023 to May 2023, without any missing values. By analyzing this dataset, we aim to gain insights into the availability of dairy products in different stores and explore potential clustering.


The summary of the dataset is presented below.

```{r}
options(knitr.kable.NA = '')
store.data %>% select(Datetime, STORE_ID, PRODUCT, AVAILABLE, Location,
`Distance from Yerevan`) %>% summary() %>% 
  kable(digits = 1) %>% 
  kable_styling(font_size = 12)
```

The dataset consists of six variables: the variable, `STORE_ID` represents the unique identifiers assigned to each store, with a total of 100 distinct stores in the dataset. The next variable, `PRODUCT` signify the three types of dairy products under investigation: Milk, Sour Cream, and Matsuni. This variable enable us to focus on the availability patterns of specific product categories across the stores.

The central variable of interest, `AVAILABLE` records the hourly count of available dairy products in each store. By examining this variable, we can observe fluctuations in stock levels and identify potential trends or seasonality in product availability. The dataset's temporal granularity, captured at an hourly level, provides a detailed perspective on the inventory dynamics within the selected timeframe.

Additionally, the last two variables in the dataset capture the geographic characteristics of the stores. The variable `Distance from Yerevan` represents the distance of each store from the capital city, Yerevan, in kilometers. This information can help us assess whether proximity to the city has any influence on product availability or demand. The variable `Location` shows provides insight into the orientation of each store concerning the country's center, further enhancing our understanding of the spatial distribution of the stores.

```{r fig.height=3,fig.width=8, message=FALSE, warning=FALSE, fig.align='center'}
g1 <- store.data %>% 
  group_by(Location) %>% 
  summarise(`Number of Stores` = n_distinct(STORE_ID),
            Percentage = n_distinct(STORE_ID)
            )  %>% 
  ggplot(aes(x = Location,
               y = `Number of Stores`, 
               fill = Location)) + 
  geom_bar( stat = "identity")+
  geom_text(mapping = aes( label = paste0(Percentage, "%")), size = 4)+
  theme_classic()+
  scale_fill_manual(values = wes_palette("GrandBudapest2", n = 4))+
  #scale_fill_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "yellow"))+
  theme(axis.text.x = element_text( vjust = 0.5))+
  labs(xlab = "")+xlab("")+
  theme(legend.position = "None")

g2 <- store.data %>%
  filter(`Distance from Yerevan`>0) %>% 
  ggplot(aes(x = `Distance from Yerevan`)) +
  geom_boxplot(fill = "lightblue")+
  xlim(c(0,120))+
  theme_bw()+
  scale_fill_brewer(palette = "Paired")+theme_bw()

ggpubr::ggarrange(g1,g2, nrow=1)
```

From the graph above it appears that the majority of the stores are located in the North part of Yerevan, comprising 65% of the total stores. Additionally, it is noteworthy that the majority of stores are located within a relatively close proximity, approximately within a 25-kilometer radius from Yerevan.


```{r fig.height=4}
store.data1 = store.data %>% filter(STORE_ID == "010", PRODUCT == "Matsuni")

g1 <- ggplot(store.data1,  aes(x = Datetime, y =  AVAILABLE, col = PRODUCT))+ 
          geom_line()  + ggtitle("") + labs(xlab="", ylab = "")+
          scale_color_brewer(palette = "Set1") + theme_bw()+ theme(legend.position = "bottom")
```

The graph above displays the hourly dynamics of the main variable for three types of products for one store. Analyzing the data, it is evident that the average replenishment frequency for all products is approximately 12 days. The average replenishment frequency of approximately 12 days indicates the store's replenishment cycle, reflecting the time required to restock and maintain adequate inventory levels. This information is essential for optimizing inventory management practices and ensuring that the store can meet customer demand efficiently. Furthermore, it is observed that the average count of available Sour Cream is consistently lower compared to the other products. The contrasting availability levels between Sour Cream and the other products suggest potential differences in consumer preferences or demand patterns. Additionally, noteworthy is the relatively similar availability levels of Milk and Matsuni for this particular store.

```{r message=FALSE, warning=FALSE}
# Demand calculation
store.data_day <- store.data %>% select(STORE_ID, PRODUCT, Datetime, everything()) %>% arrange(STORE_ID, PRODUCT, Datetime) %>% 
  group_by(STORE_ID, PRODUCT) %>% 
  mutate(Demand.Row = AVAILABLE-lead(AVAILABLE),
         Demand.Row.fill = ifelse(Demand.Row>=0, Demand.Row, (lag(Demand.Row)+lead(Demand.Row))/2)) %>% 
  ungroup() %>% 
  filter(Demand.Row.fill > 0) %>% 
  group_by(STORE_ID, PRODUCT, Date) %>% 
  summarise(Demand=sum(Demand.Row.fill, na.rm = T), 
            Location=unique(Location)) %>% 
  arrange(STORE_ID, Date)
```



```{r fig.height=4.5,fig.width=8, message=FALSE, warning=FALSE, fig.align='center'}
store.data %>% 
  group_by(Location, PRODUCT,Date) %>% 
  summarise(AVAILABLE=mean(AVAILABLE,na.rm=T)) %>%
  ggplot(aes(x = Date, y = AVAILABLE, col = PRODUCT)) +
  geom_line() +
  facet_grid(Location~.) +
  labs(x = "Date", y = "Available", col = "Product") +
  theme_bw()+
  theme(legend.position = "bottom")+
  ggtitle("Daily Average Available by Product and Region")
```


The presented graph illustrates the daily average availability of each product across different regions in the system (in all stores). It becomes apparent that Matsuni exhibits the highest availability, followed by milk, while sour cream demonstrates relatively lower demand. Moreover, it is noteworthy that the distribution of availability among regions is approximately uniform. This observation could potentially be attributed to the fact that livestock serves as the primary source of livestock production in the Republic of Armenia, with cattle breeding accounting for around 95% of milk consumption and nearly 55% of meat consumption.

In the following sections, we will delve deeper into the dataset and apply clustering techniques to unveil meaningful patterns and trends. By doing so, we strive to contribute to the field of inventory management by presenting a robust and data-driven approach for enhancing store product management strategies.

## Why DTW can be useful?

Dynamic Time Warping (DTW) is a widely used technique for measuring the similarity or distance between two time series data. Unlike the Euclidean distance, which calculates the difference between corresponding points in two time series, DTW takes into account the possible time warping or alignment of the sequences. This makes DTW particularly useful when comparing time series with variations in speed or timing.

The key advantage of DTW over Euclidean distance is its ability to handle time lags or temporal distortions between the compared sequences. In many real-world scenarios, time series data may exhibit variations in speed, phase shifts, or temporal misalignments. Euclidean distance, by strictly comparing corresponding points, may fail to capture the underlying similarities between two time series with such variations. DTW, on the other hand, allows for flexible alignment, warping, and stretching of the sequences to find the best matching pattern.

In the context of availability clustering, DTW is particularly valuable because it enables the comparison of time series data without considering the exact time lag. In inventory management, it is crucial to identify similar availability patterns across different stores, even if they do not align perfectly in terms of the time of occurrence. For instance, a new store might experience a delay in its availability pattern compared to an established store. However, the overall shape or trend of the availability pattern could still be similar. DTW allows us to capture and quantify these similarities, providing a more robust and accurate measure of clustering or similarity between availability patterns.

Moreover, DTW accommodates time series data of varying lengths, making it suitable for cases where the length of the time series may differ across stores or products. This is particularly useful when dealing with stores that have a relatively short sequence of availability data. DTW can effectively align and compare such shorter sequences with longer ones, enabling the identification of similar patterns even in cases where the time series length varies.

By leveraging the advantages of DTW, availability clustering becomes a powerful tool in inventory management. It allows for the identification of stores or products with similar availability patterns, aiding in efficient stock management, demand forecasting, and replenishment strategies. The use of DTW ensures that time lags and temporal distortions are appropriately accounted for, resulting in more accurate clustering and better decision-making processes for optimizing inventory management in diverse retail environments.

### DTW: Quickstart Example 

For the example data of 2 Stores and 1 Product will be used. To demonstrate the application of Dynamic Time Warping (DTW), the Sakoe-Chiba band^[DTW offers various types of bands, such as Itakura and Sakoe-Chiba, which define constraints for the alignment path. Additionally, bands can be learned from data. For more detailed information on these band types, I recommend referring to the original paper by Sakoe and Chiba or the article titled "Dynamic Time Warping: Itakura vs Sakoe-Chiba" by Geler, Kurbalija, et al. These resources provide comprehensive insights into the different band approaches and their applications in DTW analysis.] approach is recommended. This method constrains the warping path to reduce time complexity and enforce local alignment. By defining a band around the diagonal of the cost matrix, the alignment search space is limited, allowing for more efficient computations and improved alignment results.

The cost matrix is a fundamental component in DTW, representing the pairwise distances between individual points in the two time series being compared. Each element in the matrix corresponds to the cost of aligning two specific points. The goal of DTW is to find the optimal path through the matrix with the minimum total cost, indicating the best alignment between the time series.

```{r fig.height=4,fig.width=8, message=FALSE, warning=FALSE, fig.align='center'}
## A noisy sine wave as query
query<-store.data %>% filter(STORE_ID == "104", PRODUCT=="Matsuni") %>% select(AVAILABLE) %>% pull() %>% as.numeric()

template<-store.data %>% filter(STORE_ID == "147", PRODUCT=="Matsuni") %>% select(AVAILABLE)%>% pull() %>% as.numeric()

alignment<-dtw(query,template,keep=TRUE, window.type = "sakoechiba", window.size="Matsuni");

## Display the warping curve, i.e. the alignment curve
plot(alignment,type="threeway", main = "Time Series Alignment")
```

In the alignment path graph, the diagonal line represents the Euclidean distance, where each time point corresponds to the same time, regardless of DTW. The alignment path, shown as a curve, represents the optimal warping path determined by DTW. It captures the alignment of corresponding points in the two time series, taking into account possible time distortions or shifts.

The graph below (right one) illustrates the alignment between two time series for two stores and one type of product using the Euclidean distance. This straightforward measure compares corresponding points in the time series without considering time distortions. The alignment is achieved by connecting the points directly, resulting in a rigid alignment that may not accurately capture the underlying similarities between the time series.

```{r message=FALSE, warning=FALSE}
## A noisy sine wave as query

query<-store.data %>% filter(STORE_ID == "177", PRODUCT=="Matsuni") %>% select(AVAILABLE) %>% pull() %>% as.numeric()

template<-store.data %>% filter(STORE_ID == "147", PRODUCT=="Matsuni") %>% select(AVAILABLE)%>% pull() %>% as.numeric()

alignment2<-dtw(query,template,keep=TRUE, window.type = "sakoechiba", window.size=0)
```
![](EUC1.png)

```{r eval=FALSE, fig.height=6, include=FALSE}
par(mar = c(4, 4, .1, .1))
plot(
    alignment2,
    type="twoway")

plot(
    alignment,
    type="twoway")

```


In contrast, the right graph demonstrates the alignment between the same two time series using DTW. By allowing for warping and stretching of the sequences, DTW identifies the optimal alignment path that minimizes the total cost. This flexible alignment accounts for potential time distortions and provides a more accurate representation of the similarities between the time series.

The DTW alignment path captures the correspondence between points in the time series, allowing for variations in timing and duration. It enables the identification of similar patterns, even if the time series exhibit differences in speed or temporal alignment. The use of DTW enhances the comparison and clustering of time series data, facilitating more accurate analysis and decision-making in inventory management and other applications.

By leveraging the power of DTW and understanding its alignment capabilities, analysts can uncover valuable insights, identify patterns, and make informed decisions based on the accurate comparison of time series data.


**DTW vs Euclidean**

To compare the results of Euclidean distance and Dynamic Time Warping (DTW) in measuring similarity between time series, a simple example was considered. The example consists of three time series representing the dynamics of three stores, with one product. Time series from one store (147, red) serving as the reference and the other two (177, 178 - blue, yellow) being compared to find the most similar one.

Upon comparing these time series using both DTW and Euclidean distance metrics, interesting observations were made. When utilizing DTW, the first time series (147) was found to be closer to the third time series (178) in terms of similarity. However, based on the Euclidean distance, the first time series appeared to be closer to the second time series (177).

```{r fig.height=3,fig.width=8, message=FALSE, warning=FALSE, fig.align='center'}
## A noisy sine wave as query
query<-store.data %>% filter(STORE_ID == "147", PRODUCT=="Matsuni") %>% select(AVAILABLE) %>% pull() %>% as.numeric()
template<-store.data %>% filter(STORE_ID == "177", PRODUCT=="Matsuni") %>% select(AVAILABLE)%>% pull() %>% as.numeric()

g1 <- ggplot(store.data%>%
               filter(STORE_ID %in% c("147", "177"), PRODUCT=="Matsuni") %>% 
               mutate(STORE_ID=as.factor(STORE_ID)),
             aes(x = Datetime, y =  AVAILABLE, col = STORE_ID))+ 
          geom_line() + ggtitle("") + labs(xlab="", ylab = "", col = "")+
          #scale_color_brewer(palette = "Set1") +
  scale_color_manual(values = c("#CD534CFF","#0073C2FF" ))+
  #barplot(1:10, col = pal_jco()(10))
  theme_bw()+
  theme(legend.position = "bottom")

g2 <- ggplot(store.data%>%
               filter(STORE_ID %in% c("147", "178"), PRODUCT=="Matsuni") %>% 
               mutate(STORE_ID=as.factor(STORE_ID)), aes(x = Datetime, y =  AVAILABLE, col = STORE_ID))+ 
          geom_line() + 
    scale_color_manual(values = c("#CD534CFF", "#EFC000FF" ))+
  theme(legend.position = "bottom") + ggtitle("") + labs(xlab="", ylab = "", col = "")+
          #scale_color_brewer(palette = "Set1") +
  #scale_color_manual()
  #barplot(1:10, col = pal_jco()(10))
  theme_bw()+
  theme(legend.position = "bottom")


ggpubr::ggarrange(g1,g2, nrow=1)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
euc1_2 = dtw(query,template,keep=TRUE, window.type = "sakoechiba", window.size=0)
dtw1_2 = dtw(query,template,keep=TRUE, window.type = "sakoechiba", window.size="Matsuni");

euc1_2$distance
dtw1_2$distance
```

```{r message=FALSE, warning=FALSE}
template<-store.data %>% filter(STORE_ID == "178", PRODUCT=="Matsuni") %>% select(AVAILABLE)%>% pull() %>% as.numeric()

euc1_3 = dtw(query,template,keep=TRUE, window.type = "sakoechiba", window.size=2)
dtw1_3 = dtw(query,template,keep=TRUE, window.type = "sakoechiba", window.size="Matsuni");

#euc1_2$distance > euc1_3$distance # 1-->2
#dtw1_2$distance > dtw1_3$distance # 1-->3
# sa sran aveli mot e qan sran
```

This discrepancy in results can be attributed to the ability of DTW to account for temporal distortions and variations in the alignment of corresponding points between time series. While Euclidean distance calculates the direct differences between corresponding points, DTW allows for flexible alignment, taking into consideration time warping and stretching. 


```{r message=FALSE, warning=FALSE}
dst <- data.frame(Euclidean = c(euc1_2$distance, euc1_3$distance), DTW=c(dtw1_2$distance, dtw1_3$distance))
rownames(dst) <- c("147 <-> 177", "147 <-> 178")

options(knitr.kable.NA = '')
dst %>% kable(digits = 1) %>% 
  kable_styling(font_size = 12)
```

The calculated distances further highlight the contrasting results obtained from DTW and Euclidean distance. The observation that the DTW distance is smaller than the Euclidean distance in this example highlights the effectiveness of DTW in capturing the underlying similarity between time series. 

These findings demonstrate the importance of selecting an appropriate distance metric when comparing time series data. While Euclidean distance is straightforward and useful in certain scenarios, DTW offers a more robust approach, particularly when dealing with time series that exhibit temporal variations or misalignments. 

## Cluster Analysis using Multi-Dimensional DTW for Store Time Series

To cluster the stores based on their time series data for three different products, a **Multi-Dimensional DTW** approach was employed. This involved calculating the distance between the time series of **each product for pairs of stores**, considering not only the distance between two time series but also the distances between the corresponding product time series of two stores. By performing this comparison for all pairs of stores, a $100\text{x}100$ distance matrix was generated, providing a comprehensive measure of similarity between stores.

```{r message=FALSE, warning=FALSE}
load("distance_matrix_DTW.rda")

rownames(distance_matrix) <- str_extract(rownames(distance_matrix), pattern = "[0-9]{3}$")
colnames(distance_matrix) <- str_extract(colnames(distance_matrix), pattern = "[0-9]{3}$")

distance_matrix[10:20, 10:20]%>%as.data.frame.matrix() %>% 
  kable(digits = 1) %>% 
  kable_styling(font_size = 12)
```

Using this distance matrix, k-means clustering was applied to group the stores into clusters. The number of clusters was determined based on the optimal solution, which in this case was found to be four clusters.

The same clustering procedure was repeated using the Euclidean distance metric for comparison. To assess the quality of the clustering results, the between-cluster sum of squares (BSS) and within-cluster sum of squares (WSS) were computed. The BSS measures the separation between clusters, indicating how distinct the clusters are from each other, while the WSS quantifies the compactness of each cluster. By evaluating the BSS and WSS values, we can determine the effectiveness of the clustering approach.

The centroid of each cluster represents the **typical time series** pattern for that cluster. In this case, the centroid products, which are the time series representing the centroid of each cluster, were selected to represent the cluster's characteristics. By examining these centroid products, we can gain insights into the common patterns exhibited within each cluster.


Although the results of the comparison between DTW and Euclidean distances for clustering the store time series were relatively similar, the decision was made to utilize DTW as the preferred distance metric. This choice was based on the unique capabilities of DTW in handling time series data with variations in time alignment. In the context of store time series clustering, DTW provides a more robust measure of similarity. 

```{r message=FALSE, warning=FALSE}
# Perform k-means clustering on the distance matrix
k <- 4  # Number of clusters
set.seed(123)  # Set a random seed for reproducibility
kmeans_result <- kmeans(distance_matrix, centers = k, nstart = 1000)

# Print the cluster assignments
cluster_assignments <- kmeans_result$cluster
#print(cluster_assignments)

store.data <- left_join(mutate(store.data,STORE_ID=as.character(STORE_ID)), data.frame(STORE_ID = names(cluster_assignments), CLUSTER_DTW = as.factor(as.numeric(cluster_assignments)))) 
```

```{r fig.height=4,fig.width=8, message=FALSE, warning=FALSE, fig.align='center'}
store.data %>% 
  group_by(CLUSTER_DTW,PRODUCT,Datetime) %>% 
  summarise(AVAILABLE=mean(AVAILABLE,na.rm=T)) %>% 
ggplot(aes(x = Datetime, y = AVAILABLE, col = PRODUCT)) +
  geom_line() +
  facet_wrap(~ CLUSTER_DTW, scales = "free") +
  labs(x = "Date", y = "Available", col = "Product") +
  theme_bw()+
  theme(legend.position = "bottom")+
  ggtitle("Cluster Analysis Results (Multi-Dimensional DTW)")
```




```{r message=FALSE, warning=FALSE}
### EUC
load("distance_matrix_EUC.rda")
rownames(distance_matrix_EUC) <- str_extract(rownames(distance_matrix_EUC), pattern = "[0-9]{3}$")
colnames(distance_matrix_EUC) <- str_extract(colnames(distance_matrix_EUC), pattern = "[0-9]{3}$")

# Perform k-means clustering on the distance matrix
k <- 4  # Number of clusters
set.seed(123)  # Set a random seed for reproducibility
kmeans_result <- kmeans(distance_matrix_EUC, centers = k, nstart = 1000)

# Print the cluster assignments
cluster_assignments <- kmeans_result$cluster
#print(cluster_assignments)

store.data <- left_join(mutate(store.data,STORE_ID=as.character(STORE_ID)), data.frame(STORE_ID = names(cluster_assignments), CLUSTER_EUC = as.factor(as.numeric(cluster_assignments)))) 
```




```{r message=FALSE, warning=FALSE, include=FALSE}
# Comparing Results and choosing one of them, speaking about BSS and WSS
# 
# - DTW 
# 
# - EUC

WSS_By_Cluster =store.data %>% 
  group_by(CLUSTER_DTW,PRODUCT,Datetime) %>% 
  mutate(Centroid=mean(AVAILABLE,na.rm=T)) %>% 
  ungroup() %>% 
  group_by(CLUSTER_DTW) %>% 
  summarise(WSS = sum((AVAILABLE - Centroid)^2))

BSS_By_Cluster  = store.data %>% 
  group_by(Datetime, PRODUCT) %>% 
  mutate(General_Mean = mean(AVAILABLE,na.rm=T)) %>% 
  ungroup() %>% 
  group_by(CLUSTER_DTW,PRODUCT,Datetime) %>% 
  summarise(Centroid=mean(AVAILABLE,na.rm=T), General_Mean=unique(General_Mean)) %>%
  ungroup() %>% 
  group_by(CLUSTER_DTW, PRODUCT) %>% 
  summarise(BSS = sum((Centroid - General_Mean)^2)) %>% 
  group_by(CLUSTER_DTW) %>% 
  summarise(BSS =sum(BSS))

(BSS_By_Cluster$BSS %>% sum() )/ (WSS_By_Cluster$WSS %>% sum())
# 0.0204


WSS_By_Cluster =store.data %>% 
  group_by(CLUSTER_EUC,PRODUCT,Datetime) %>% 
  mutate(Centroid=mean(AVAILABLE,na.rm=T)) %>% 
  ungroup() %>% 
  group_by(CLUSTER_EUC) %>% 
  summarise(WSS = sum((AVAILABLE - Centroid)^2))

BSS_By_Cluster  = store.data %>% 
  group_by(Datetime, PRODUCT) %>% 
  mutate(General_Mean = mean(AVAILABLE,na.rm=T)) %>% 
  ungroup() %>% 
  group_by(CLUSTER_EUC,PRODUCT,Datetime) %>% 
  summarise(Centroid=mean(AVAILABLE,na.rm=T), General_Mean=unique(General_Mean)) %>%
  ungroup() %>% 
  group_by(CLUSTER_EUC, PRODUCT) %>% 
  summarise(BSS = sum((Centroid - General_Mean)^2)) %>% 
  group_by(CLUSTER_EUC) %>% 
  summarise(BSS =sum(BSS))

(BSS_By_Cluster$BSS %>% sum() )/ (WSS_By_Cluster$WSS %>% sum())

#0.0229
```

The results, depicted in the graph above, showcase the four clusters, with each cluster represented separately. Within each cluster, three time series are represented as centroid products, providing a concise summary of the time series patterns for that cluster.

Multi-Dimensional DTW analysis offers a comprehensive understanding of the similarity between store time series for different products.

**Describing Product Dynamics**

Before delving into a detailed description of the clusters and their geographic characteristics, let's explore the dynamics of each product within the clusters. To achieve this, we will examine the 7-day moving average availability dynamics of each product across the entire system, segmented by clusters. The graph presented below illustrates the time series dynamics for each product (arranged in rows), with the colored lines representing the differences in clusters.

Analyzing the dynamics of Matsuni availability, it becomes evident that clusters 3 and 4 exhibit significantly higher dynamics compared to clusters 1 and 2. This suggests that stores within clusters 3 and 4 have distinct patterns of availability for Matsuni, potentially indicating variations in demand or stocking strategies within these clusters. Similarly, the dynamics of milk availability differ noticeably across the clusters. Cluster 1 stands out with considerably lower availability dynamics compared to the other clusters, implying a distinct pattern in milk availability for the stores within this cluster.


```{r fig.height=4,fig.width=8, message=FALSE, warning=FALSE, fig.align='center'}
store.data %>% 
  group_by(CLUSTER_DTW,PRODUCT,Datetime) %>% 
  summarise(AVAILABLE=mean(AVAILABLE,na.rm=T)) %>% 
  ungroup()%>% 
   mutate(Rolling_avg = rollmean(AVAILABLE, k=9*7, fill=NA, align='right')) %>% 
ggplot(aes(x = Datetime, y = Rolling_avg, col = CLUSTER_DTW)) +
  geom_line() +
  facet_grid(PRODUCT~., scales = "free") +
  labs(x = "Date", y = "Available", col = "Cluster") +
  theme_bw()+
  theme(legend.position = "bottom")+
  ggtitle("Product's Dynamics by Clusters (7-days MA)")+
  scale_color_brewer(palette = "Dark2")
```


Turning our attention to Sour Cream, the stores within cluster 3 display a distinctive and higher pattern of availability dynamics compared to stores in the other clusters. This suggests that cluster 3 stores may have unique factors influencing the availability of Sour Cream, such as different sourcing or demand patterns, when compared to the stores in the remaining clusters.


## Exploring Store Clusters and Regional Distribution

### Describing Clusters

In this section, we will provide a description of the clusters by utilizing the prototypes or cluster centroids derived from the available time series data. In order to uncover distinct patterns and characteristics to each cluster the 7-day moving average of each product's availability within each cluster will be used.

As mentioned earlier, the availability of dairy products serves as a reliable proxy for understanding consumer demand. In essence, we can use the terms "availability" and "demand" interchangeably when discussing dairy product dynamics.

**Cluster 1: High Demand for Matsuni and Milk with Low Sour Cream Consumption**

The first cluster stands out with a high availability of Matsuni and Milk dynamics, showcasing a relatively similar level of availability for both products. However, the availability of sour cream within this cluster is notably lower. This cluster represents stores with a strong demand for Matsuni and milk, while the demand for sour cream is comparatively lower.

**Cluster 2: High Demand and Active Stores**

This cluster represents highly active stores with a substantial demand for all three dairy products. Additionally, the general trend of product availability within this cluster is higher, further emphasizing the dynamic nature of these stores.


```{r fig.height=4,fig.width=8, message=FALSE, warning=FALSE, fig.align='center'}
store.data %>% 
  group_by(CLUSTER_EUC,PRODUCT,Datetime) %>% 
  summarise(AVAILABLE=mean(AVAILABLE,na.rm=T)) %>% 
   mutate(Rolling_avg = rollmean(AVAILABLE, k=9*7, fill=NA, align='right')) %>% 
ggplot(aes(x = Datetime, y = Rolling_avg, col = PRODUCT)) +
  geom_line() +
  facet_wrap(~ CLUSTER_EUC, scales = "free") +
  labs(x = "Date", y = "Available", col = "Product") +
  theme_bw()+
  theme(legend.position = "bottom")+
  ggtitle("Cluster Analysis Results (Multi-Dimensional DTW), 7-days MA")
```

**Cluster 3: Similar Availability for Milk and Matsuni with Fluctuating Sour Cream Availability**

In Cluster 3, the availability of milk and Matsuni displays a similar pattern to that observed in Cluster 1. However, it is worth noting that the availability of sour cream experiences fluctuations around a level of approximately 15, particularly from April onwards. This cluster represents stores where the demand for milk and Matsuni is relatively consistent, while the availability of sour cream exhibits more variability.


**Cluster 4: Less Active Stores with Focus on Matsuni Consumption**

Cluster 4 comprises the least active stores, characterized by a higher consumption of Matsuni compared to milk and sour cream. The dynamics of milk and sour cream availability in this cluster are relatively low compared to the other clusters. This cluster represents stores where Matsuni consumption takes precedence, with milk and sour cream playing lesser roles.


### Regional Distribution of Clusters

Moving beyond the analysis of product dynamics, it is equally important to explore the regional distribution of the clusters. This examination sheds light on the characteristics of stores within each region, enabling us to discern the specific types of stores present in different regions. 


The geographical analysis reveals interesting patterns in the distribution of clusters across different regions of Armenia. The plot below demonstrates that the South region, encompassing both the West and East areas, predominantly comprises stores belonging to cluster 2, characterized by high activity levels. This suggests that stores situated in the southwestern part of the country exhibit a strong demand for all three products. Conversely, the northeastern region of Armenia accommodates stores from both the most active cluster and the least active cluster.



```{r fig.height=3,fig.width=8, message=FALSE, warning=FALSE, fig.align='center'}
g1 <- store.data %>% 
  group_by(Location, CLUSTER_DTW) %>% 
  summarise(`Number of Stores` = n_distinct(STORE_ID)) %>% 
  group_by(Location) %>% 
  mutate(Percentage = round(`Number of Stores` / sum(`Number of Stores`)*100)) %>% 
  mutate(CLUSTER_DTW = factor(CLUSTER_DTW)) %>% 
  ggplot(aes(x = Location,
               y = `Number of Stores`, 
               fill = CLUSTER_DTW)) + 
  geom_bar(stat = "identity", position = "fill", alpha = 0.7)+
  geom_text(mapping = aes(label = paste0( Percentage, "%")), 
            position = position_fill(vjust = 0.5), size = 3)+
  theme_classic()+
  scale_fill_manual(values = c("#E41A1C", "#377EB8", "#4DAF4A", "yellow"))+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))+
  labs(xlab = "",ylab = "", fill = "Cluster")+coord_flip()+xlab("")+ylab("")+
  theme(legend.position = "bottom")+
  scale_fill_brewer(palette = "Dark2")

g2 <- store.data %>% select(STORE_ID, `Distance from Yerevan`, Location, CLUSTER_DTW) %>%
  mutate(CLUSTER_DTW = as.factor(CLUSTER_DTW)) %>%
  distinct() %>%
  ggplot(aes(x = `Distance from Yerevan`,
               y = CLUSTER_DTW,
               fill = CLUSTER_DTW)) +
  geom_boxplot(alpha = 0.7)+
  coord_flip()+xlim(c(0,50))+
  theme_bw()+ylab("")+
  scale_fill_brewer(palette = "Dark2")

ggpubr::ggarrange(g1,g2, nrow=1, common.legend = TRUE, legend="bottom")
```



Furthermore, a general observation can be made regarding the proximity of stores to Yerevan, the capital city. Stores located in close proximity to Yerevan exhibit higher levels of demand dynamics for all product types, as evident in clusters 1 and 2. In contrast, stores situated farther away demonstrate lower availability levels and less frequent replenishment. This discrepancy can be attributed to the self-sustaining demand of rural areas and less active regions compared to urban centers.

These findings provide valuable insights into the regional distribution of store clusters and the varying dynamics of product availability and demand across different parts of Armenia. By understanding these regional variations, businesses can tailor their strategies to cater to the specific needs and preferences of customers in each area.

## Optimal Order Quantity for each cluster and product

As mentioned in the introduction, the objective of this research is to address inventory management challenges by determining the optimal quantity of each product for different groups of stores. One of the key concepts utilized in this context is the Economic Order Quantity (EOQ). The EOQ represents the ideal order quantity that minimizes the total inventory costs, taking into account factors such as ordering costs, carrying costs, and demand.

The specific calculation of the EOQ for each product is presented below. 

**EOQ**


* T = total annual inventory cost
* P = purchase unit price, unit production cost
* Q = order quantity
* Q* = optimal order quantity
* D = annual demand quantity
* K = fixed cost per order
* h = annual holding cost per unit

The total cost function and derivation of EOQ formula: 


$${\displaystyle  \text{Total Cost = Purchase cost + Ordering cost + Holding cost}}$$

* Purchase cost is the variable cost of goods
* Ordering cost is the cost of placing orders
* Holding cost is the average quantity in stock (between fully replenished and empty) is Q/2


$${\displaystyle T=PD+K{\frac {D}{Q}}+h{\frac {Q}{2}}}$$

Economic order quantity (EOQ) formula is often stated as. 

$$EOQ = \sqrt{\frac{2DK}{H}}$$

Where D is annual demand quantity. Note that Q* is independent of P; it is a function of only K, D, h.

It is important to note that these calculations serve as a simplified demonstration and are not an exhaustive representation of the complexities involved in inventory management. Therefore, the presented EOQ calculations provide a starting point for inventory management optimization. In practice, a more comprehensive approach would consider various factors such as seasonality, dynamic EOQ adjustments, and other relevant considerations. By incorporating these additional factors, a more refined and accurate approach to inventory management can be achieved. 



**Calculating optimal quantity for Product-Cluster Combinations**

In order to determine the optimal quantity (EOQ) for each product in each cluster, several inputs are required. These inputs include the annual demand quantity, fixed cost per order, and annual holding cost per unit. By utilizing these inputs, we can calculate the EOQ values that minimize the total inventory costs and maximize profitability.


The results of these calculations are depicted in the graph below, which illustrates the dynamic demand patterns for each product within each cluster. The solid lines on the graph represent the optimal order quantities determined by the EOQ calculations.


```{r fig.height=4,fig.width=8, message=FALSE, warning=FALSE, fig.align='center'}
# EOQ <- store.data_day %>% 
#   group_by(CLUSTER_DTW,PRODUCT,Date) %>% 
#   summarise(Demand=mean(Demand,na.rm=T)) %>%
#   ungroup() %>% 
#   group_by(CLUSTER_DTW,PRODUCT) %>% 
#   summarise(Demand=round(sum(Demand,na.rm=T))) %>% 
#   ungroup() %>% 
#  group_by(CLUSTER_DTW,PRODUCT) %>% 
#   summarise(EOQ = round(sqrt(2*Demand*2000/100000))) %>% 
#   ungroup()
#   
  
EOQ = store.data_day %>%
  mutate(Demand = rollmean(Demand, k=7, fill=NA, align='right')) %>% 
  left_join(distinct(select(store.data, CLUSTER_DTW, STORE_ID))) %>% 
  group_by(CLUSTER_DTW,PRODUCT,Date) %>% 
  summarise(Demand=mean(Demand,na.rm=T)) %>%
  ungroup() %>% 
  group_by(CLUSTER_DTW,PRODUCT)%>%
  summarise(EOQ=quantile(Demand,na.rm=T, p=0.9)) %>%
  ungroup()
  
store.data_day %>%
  mutate(Demand = rollmean(Demand, k=7, fill=NA, align='right')) %>% 
  left_join(distinct(select(store.data, CLUSTER_DTW, STORE_ID))) %>% 
  group_by(CLUSTER_DTW,PRODUCT,Date) %>% 
  summarise(Demand=mean(Demand,na.rm=T)) %>% 
  ungroup() %>% 
  left_join(EOQ) %>% 
  # mutate(Rolling_avg = rollmean(Demand, k=9*7*2, fill=NA, align='right')) %>% 
ggplot(aes(x = Date, y = Demand, col = PRODUCT)) +
  geom_line(lty = 2) +
  geom_line(aes(x = Date, y = EOQ, col = PRODUCT), lwd = 0.7) +
  facet_wrap(~ CLUSTER_DTW, scales = "free") +
  labs(x = "Date", y = "Demand", col = "Product") +
  theme_bw()+
  theme(legend.position = "bottom")+
  ggtitle("Daily Average Demand by Clusters and Optimal Quantity")
```

Understanding the EOQ for each product in each cluster is highly beneficial in terms of inventory control and decision-making. By knowing the optimal order quantities, businesses can avoid excessive stockouts or overstocking, leading to improved customer satisfaction and reduced holding costs. Furthermore, having accurate EOQ values allows businesses to optimize their procurement processes, streamline operations, and allocate resources effectively.

Overall, the utilization of EOQ provides businesses with a statistical approach to inventory management, enabling them to make data-driven decisions that enhance efficiency, profitability, and customer service levels.

## Conclusion


In the study, we addressed the problem of inventory management by leveraging clustering techniques and calculating the Economic Order Quantity for different product-cluster combinations. Our aim was to provide insights and solutions for effectively managing inventory in a retail setting.

We utilized a dataset consisting of availability data from 100 stores, each offering three distinct products. By employing Multi-Dimensional Dynamic Time Warping (DTW) techniques, we performed clustering analysis on the time series data to identify similar patterns and group stores accordingly. This allowed us to gain a deeper understanding of the underlying dynamics within the retail system.

Multi-Dimensional DTW analysis offers a comprehensive understanding of the similarity between store time series for different products. Such insights can be instrumental in inventory management, demand forecasting, and decision-making processes within the retail industry. The statistical rigor of this approach ensures a robust analysis of the store time series data, enabling data-driven strategies for store grouping and optimization.

The resulting clusters provided valuable insights into the stores' availability dynamics and demand patterns. Each cluster represented a distinct group of stores with unique characteristics. By examining the centroid time series for each cluster, we were able to interpret the behavior and trends specific to the products within those clusters. 

Moreover, we calculated the EOQ for each product within each cluster. By considering factors such as annual demand quantity, fixed cost per order, and annual holding cost per unit, we determined the optimal order quantity for inventory replenishment. The EOQ results were plotted alongside the demand dynamics, providing a visual representation of the recommended order quantities for each product-cluster combination.

The implications of this research are significant for businesses operating in the retail industry. By leveraging clustering techniques and EOQ analysis, retailers can effectively allocate resources and optimize their inventory management strategies. The identified clusters provide a basis for targeted decision-making, allowing retailers to tailor their inventory levels and replenishment strategies based on the specific characteristics of each cluster. This, in turn, can lead to improved operational efficiency, reduced costs, and enhanced customer satisfaction.



## References

 1. Geler Z., Kurbalija V., Ivanovic M., 2019, Radovanovic M., Dai W.,   "Dynamic Time Warping: Itakura vs Sakoe-Chiba"
 2. Sakoe H., Chiba S., 1978, "Dynamic Programming Algorithm Optimization for Spoken Word Recognition"
 3. Shokoohi-Yekta M., Hu B., Jin B., Wang J., Keogh E., 2015, "Generalizing Dynamic Time Warping to the Multi-Dimensional Case Requires an Adaptive Approach"

